{"cells":[{"metadata":{"_uuid":"70df53e2d945b1bc315a07f8f5c000ced37cc3a5"},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09fc2d287226427a04eeb870c92304c6a0c05fb3"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"55844c0e2ffe7499ec338a470514a462e21c72bd"},"cell_type":"markdown","source":"# Import Data"},{"metadata":{"_uuid":"27d4fbccb27690c1ffcdf252429f7b82d0c74c0f"},"cell_type":"markdown","source":"## Review Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"pics = np.load(\"../input/olivetti_faces.npy\")\nlabels = np.load(\"../input/olivetti_faces_target.npy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b95b68f1d54768b745ad361b51191da5475258a7"},"cell_type":"code","source":"print(\"pics: \", pics.shape)\nprint(\"labels: \", labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f88d8ecba36dc70d5410f949847c2a3fda93cc68"},"cell_type":"code","source":"fig = plt.figure(figsize=(20, 10))\ncolumns = 10\nrows = 4\nfor i in range(1, columns*rows +1):\n    img = pics[10*(i-1),:,:]\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img, cmap = plt.get_cmap('gray'))\n    plt.title(\"person {}\".format(i), fontsize=16)\n    plt.axis('off')\n    \nplt.suptitle(\"There are 40 distinct people in the dataset\", fontsize=22)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55cecc039629eaac213415701e0d50d48b66ee7f"},"cell_type":"code","source":"Xdata = pics # store images in Xdata\nYdata = labels.reshape(-1,1) # store labels in Ydata","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cb0cea43d2c739e1508e182b43764a157051da9"},"cell_type":"markdown","source":"## Split data for train and test purposes"},{"metadata":{"trusted":true,"_uuid":"20aa318477cd4abd42c2440f2ffea1f9bdfb15cb","scrolled":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(Xdata, Ydata, test_size = 0.2, random_state=46)\n\nprint(\"x_train: \",x_train.shape)\nprint(\"x_test: \",x_test.shape)\nprint(\"y_train: \",y_train.shape)\nprint(\"y_test: \",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1efc564edc673ee9ac1040c220aa2b463e7680bb"},"cell_type":"markdown","source":"### Reshape"},{"metadata":{"trusted":true,"_uuid":"7ad9c5cd0e4f80875451d0fb1b6a3dec569dee3a"},"cell_type":"code","source":"x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\nx_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n\nprint(\"x_train: \",x_train.shape)\nprint(\"x_test: \",x_test.shape)\nprint(\"y_train: \",y_train.shape)\nprint(\"y_test: \",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe5fa333d970e90a1164001242a5a3c12098b793"},"cell_type":"code","source":"# Store accuracies of the machine learning methods for comparison at the end\nlist_names = []\nlist_accuracy = []","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9e2e78713457ada128aa39e7a54f29cf42318be"},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"50e91f3070d5e3d673bddc92bf0494c3379094d6"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(max_iter=1000)\nlr.fit(x_train, y_train)\nLR_accuracy = round(lr.score(x_test, y_test)*100,2)\n\nprint(\"LR_accuracy is %\", LR_accuracy)\n\nlist_names.append(\"Logistic Regression\")\nlist_accuracy.append(LR_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e0407d7b20b0eb6cb33aba2903782fb4a393748"},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true,"_uuid":"80bca772e38713e715728947eeece414e4458aef"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nrf = RandomForestClassifier(n_estimators = 400, random_state = 1)\nrf.fit(x_train, y_train)\nRF_accuracy = round(rf.score(x_test, y_test)*100,2)\n\nprint(\"RF_accuracy is %\", RF_accuracy)\n\nlist_names.append(\"Random Forest\")\nlist_accuracy.append(RF_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"984f2b8abb0911e1bcf23c791357e4c244e41e2f"},"cell_type":"markdown","source":"# K-NN Classifier"},{"metadata":{"trusted":true,"_uuid":"96ea2ceeb1cd571bac2ec7c337a34a456cf58eb7"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nKnn = KNeighborsClassifier(n_neighbors = 1) # n_neighbors=1 gives the best result for this data\nKnn.fit(x_train, y_train)\nKnn_accuracy = round(Knn.score(x_test, y_test)*100,2)\n\nprint(\"Knn_accuracy is %\", Knn_accuracy)\n\nlist_names.append(\"KNN\")\nlist_accuracy.append(Knn_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"987340c9904f2a54899042ee9ba4cdcbdf9e7aab"},"cell_type":"markdown","source":"# Convolutional Neural Network (CNN)"},{"metadata":{"_uuid":"5f7265ae36f6681d041bf7c1640c459ef7c21b83"},"cell_type":"markdown","source":"### Reshape for CNN"},{"metadata":{"trusted":true,"_uuid":"c4c1bd6919a32e733cd0846f6062ae37cd49d01b"},"cell_type":"code","source":"x_train = x_train.reshape(-1,64,64,1)\nx_test = x_test.reshape(-1,64,64,1)\n\nprint(\"x_train: \",x_train.shape)\nprint(\"x_test: \",x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f179b65743285f0b1efb003587c11b6daeeda44"},"cell_type":"markdown","source":"### Label Encoding "},{"metadata":{"trusted":true,"_uuid":"92a56f00f3a690bc509295bd519ae1e4c3127dae"},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n\ny_train_ = to_categorical(y_train, num_classes = 40) # 40 distinct people\ny_test_ = to_categorical(y_test, num_classes = 40)\n\nprint(\"y_train_ shape: \",y_train_.shape)\nprint(\"y_test_ shape: \",y_test_.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fb27564ae52044c2c2f6d03bf199aa6d67b9682","scrolled":false},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 20, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (64,64,1)))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 50, kernel_size = (6,6),padding = 'Same', \n                 activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 150, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (64,64,1)))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(40, activation = \"softmax\"))\n\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.7, \n                                            min_lr=0.00000000001)\n\nepoch = 37\nbatch_size = 20\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.05, # Randomly zoom image \n        width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(x_train)\n\nhistory = model.fit_generator(\n                              datagen.flow(x_train,y_train_, batch_size=batch_size),\n                              epochs = epoch, \n                              validation_data = (x_test,y_test_),\n                              verbose = 2, \n                              steps_per_epoch=x_train.shape[0] // batch_size,\n                              callbacks=[learning_rate_reduction]\n                             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f18290c1fd46daf329c3010079048dfd2ce1814b"},"cell_type":"code","source":"y_pred = model.predict_classes(x_test)\n\ny_test = y_test.reshape(-1,)\n\ndiff = y_test - y_pred\ndiff = diff.reshape(-1,1)\n\ntrue = 0\nfor i in range(0,len(diff)):\n    if diff[i] == 0:\n        true = true + 1\n\nCnn_accuracy = round(100*true/len(diff),2)\n\nprint(\"Cnn_accuracy is %\", Cnn_accuracy)\n\nlist_names.append(\"CNN\")\nlist_accuracy.append(Cnn_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56951b083428f1b6c8f78288a8633c2ed22c55a8"},"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nval_accuracy = history.history['val_acc']\n\naccuracy = []\nnum_of_epochs = []\nfor i in range(1,epoch,4):\n    accuracy.append(round(100*val_accuracy[i],3))\n    num_of_epochs.append(i)\n\ntrace1 = go.Scatter(y = accuracy, x = num_of_epochs, mode = \"lines\")\ndata = [trace1]\nlayout = dict(title = 'CNN Accuracy',\n              autosize=False,\n              width=800,\n              height=500,\n              yaxis= dict(title= 'Accuracy (%)',gridwidth=2, gridcolor='#bdbdbd'),\n              xaxis= dict(title= 'Number of Epochs',gridwidth=2, gridcolor='#bdbdbd'),\n              font=dict(size=14)\n             )\nfig = dict(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1439004cff8109ef52e53cb9d8e01f7af7e91deb"},"cell_type":"markdown","source":"# Comparison of the Learning Methods"},{"metadata":{"trusted":true,"_uuid":"8652b49c19e59b75a8d0c9599eb5e232f6c01dad"},"cell_type":"code","source":"df = pd.DataFrame({'METHOD': list_names, 'ACCURACY (%)': list_accuracy})\ndf = df.sort_values(by=['ACCURACY (%)'])\ndf = df.reset_index(drop=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4779c9689e184a50b9e8542ba973a8655035bf4b"},"cell_type":"code","source":"trace1 = go.Bar(x = df.iloc[:,0].tolist(), y = df.iloc[:,1].tolist())\n\ndata1 = [trace1]\nlayout1 = go.Layout(\n    title='Comparison of the Learning Methods',\n    xaxis=dict(titlefont=dict(size=16)),\n    yaxis=dict(title='ACCURACY (%)',gridwidth=1, gridcolor='#bdbdbd', range=[89, 99]),\n    font=dict(size=16),\n    bargap = 0.7,\n    barmode='group')\n\nfig = go.Figure(data=data1, layout=layout1)\npy.iplot(fig, filename='grouped-bar')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}