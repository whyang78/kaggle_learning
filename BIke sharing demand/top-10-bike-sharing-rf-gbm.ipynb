{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bike-sharing-demand/train.csv\n",
      "/kaggle/input/bike-sharing-demand/sampleSubmission.csv\n",
      "/kaggle/input/bike-sharing-demand/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for name in ['train','test']:\n",
    "    df = pd.read_csv('/kaggle/input/bike-sharing-demand/%s.csv' % name)\n",
    "    df['_data'] = name\n",
    "    dfs[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train and test data into one df\n",
    "df = dfs['train'].append(dfs['test'])\n",
    "\n",
    "# lowercase column names\n",
    "df.columns = map(str.lower, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logarithmic transformation of dependent cols\n",
    "# (adding 1 first so that 0 values don't become -inf)\n",
    "for col in ['casual', 'registered', 'count']:\n",
    "    df['%s_log' % col] = np.log(df[col] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse datetime colum & add new time related columns\n",
    "dt = pd.DatetimeIndex(df['datetime'])\n",
    "df.set_index(dt, inplace=True)\n",
    "\n",
    "df['date'] = dt.date\n",
    "df['day'] = dt.day\n",
    "df['month'] = dt.month\n",
    "df['year'] = dt.year\n",
    "df['hour'] = dt.hour\n",
    "df['dow'] = dt.dayofweek\n",
    "df['woy'] = dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_day(day_start):\n",
    "#    day_end = day_start + pd.offsets.DateOffset(hours=23)\n",
    "#    return pd.date_range(day_start, day_end, freq=\"H\")\n",
    "\n",
    "# tax day\n",
    "#df.loc[get_day(pd.datetime(2011, 4, 15)), \"workingday\"] = 1\n",
    "#df.loc[get_day(pd.datetime(2012, 4, 16)), \"workingday\"] = 1\n",
    "# thanksgiving friday\n",
    "#df.loc[get_day(pd.datetime(2011, 11, 25)), \"workingday\"] = 0\n",
    "#df.loc[get_day(pd.datetime(2012, 11, 23)), \"workingday\"] = 0\n",
    "# tax day\n",
    "#df.loc[get_day(pd.datetime(2011, 4, 15)), \"holiday\"] = 0\n",
    "#df.loc[get_day(pd.datetime(2012, 4, 16)), \"holiday\"] = 0\n",
    "\n",
    "# thanksgiving friday\n",
    "#df.loc[get_day(pd.datetime(2011, 11, 25)), \"holiday\"] = 1\n",
    "#df.loc[get_day(pd.datetime(2012, 11, 23)), \"holiday\"] = 1\n",
    "\n",
    "#storms\n",
    "#df.loc[get_day(pd.datetime(2012, 5, 21)), \"holiday\"] = 1\n",
    "#tornado\n",
    "#df.loc[get_day(pd.datetime(2012, 6, 1)), \"holiday\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['peak'] = df[['hour', 'workingday']].apply(lambda x: (0, 1)[(x['workingday'] == 1 and  ( x['hour'] == 8 or 17 <= x['hour'] <= 18 or 12 <= x['hour'] <= 13)) or (x['workingday'] == 0 and  10 <= x['hour'] <= 19)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#sandy\n",
    "df['holiday'] = df[['month', 'day', 'holiday', 'year']].apply(lambda x: (x['holiday'], 1)[x['year'] == 2012 and x['month'] == 10 and (x['day'] in [30])], axis = 1)\n",
    "\n",
    "#christmas day and others\n",
    "df['holiday'] = df[['month', 'day', 'holiday']].apply(lambda x: (x['holiday'], 1)[x['month'] == 12 and (x['day'] in [24, 26, 31])], axis = 1)\n",
    "df['workingday'] = df[['month', 'day', 'workingday']].apply(lambda x: (x['workingday'], 0)[x['month'] == 12 and x['day'] in [24, 31]], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['ideal'] = df[['temp', 'windspeed']].apply(lambda x: (0, 1)[x['temp'] > 27 and x['windspeed'] < 30], axis = 1)\n",
    "df['sticky'] = df[['humidity', 'workingday']].apply(lambda x: (0, 1)[x['workingday'] == 1 and x['humidity'] >= 60], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "\n",
    "def get_rmsle(y_pred, y_actual):\n",
    "    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    data = df[df['_data'] == 'train'].copy()\n",
    "    return data\n",
    "\n",
    "\n",
    "def custom_train_test_split(data, cutoff_day=15):\n",
    "    train = data[data['day'] <= cutoff_day]\n",
    "    test = data[data['day'] > cutoff_day]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def prep_data(data, input_cols):\n",
    "    X = data[input_cols]\n",
    "    y_r = data['registered_log']\n",
    "    y_c = data['casual_log']\n",
    "\n",
    "    return X, y_r, y_c\n",
    "\n",
    "\n",
    "def predict_on_validation_set(model, input_cols):\n",
    "    data = get_data()\n",
    "\n",
    "    train, test = custom_train_test_split(data)\n",
    "\n",
    "    X_train, y_train_r, y_train_c = prep_data(train, input_cols)\n",
    "    X_test, y_test_r, y_test_c = prep_data(test, input_cols)\n",
    "\n",
    "    model_r = model.fit(X_train, y_train_r)\n",
    "    y_pred_r = np.exp(model_r.predict(X_test)) - 1\n",
    "\n",
    "    model_c = model.fit(X_train, y_train_c)\n",
    "    y_pred_c = np.exp(model_c.predict(X_test)) - 1\n",
    "\n",
    "    y_pred_comb = np.round(y_pred_r + y_pred_c)\n",
    "    y_pred_comb[y_pred_comb < 0] = 0\n",
    "\n",
    "    y_test_comb = np.exp(y_test_r) + np.exp(y_test_c) - 2\n",
    "\n",
    "    score = get_rmsle(y_pred_comb, y_test_comb)\n",
    "    return (y_pred_comb, y_test_comb, score)\n",
    "\n",
    "df_test = df[df['_data'] == 'test'].copy()\n",
    "\n",
    "# predict on test set & transform output back from log scale\n",
    "def predict_on_test_set(model, x_cols):\n",
    "    # prepare training set\n",
    "    df_train = df[df['_data'] == 'train'].copy()\n",
    "    X_train = df_train[x_cols]\n",
    "    y_train_cas = df_train['casual_log']\n",
    "    y_train_reg = df_train['registered_log']\n",
    "\n",
    "    # prepare test set\n",
    "    X_test = df_test[x_cols]\n",
    "\n",
    "    casual_model = model.fit(X_train, y_train_cas)\n",
    "    y_pred_cas = casual_model.predict(X_test)\n",
    "    y_pred_cas = np.exp(y_pred_cas) - 1\n",
    "    registered_model = model.fit(X_train, y_train_reg)\n",
    "    y_pred_reg = registered_model.predict(X_test)\n",
    "    y_pred_reg = np.exp(y_pred_reg) - 1\n",
    "    # add casual & registered predictions together\n",
    "    return y_pred_cas + y_pred_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44130236175493526\n"
     ]
    }
   ],
   "source": [
    "# random forest model\n",
    "params = {'n_estimators': 1000, 'max_depth': 15, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\n",
    "rf_model = RandomForestRegressor(**params)\n",
    "rf_cols = [\n",
    "    'weather', 'temp', 'atemp', 'windspeed',\n",
    "    'workingday', 'season', 'holiday', 'sticky',\n",
    "    'hour', 'dow', 'woy', 'peak',\n",
    "]\n",
    "rf_p, rf_t, rf_score = predict_on_validation_set(rf_model, rf_cols)\n",
    "print(rf_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32114136782119973\n",
      "0.32423520881802764\n"
     ]
    }
   ],
   "source": [
    "# GBM model\n",
    "params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
    "gbm_model = GradientBoostingRegressor(**params)\n",
    "gbm_cols = [\n",
    "    'weather', 'temp', 'atemp', 'humidity', 'windspeed',\n",
    "    'holiday', 'workingday', 'season',\n",
    "    'hour', 'dow', 'year', 'ideal'\n",
    "    ]\n",
    "\n",
    "\n",
    "(gbm_p, gbm_t, gbm_score) = predict_on_validation_set(gbm_model, gbm_cols)\n",
    "print(gbm_score)\n",
    "\n",
    "# the blend gives a better score on the leaderboard, even though it does not on the validation set\n",
    "y_p = np.round(.2*rf_p + .8*gbm_p)\n",
    "print(get_rmsle(y_p, rf_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predctions on test dataset\n",
    "rf_pred = predict_on_test_set(rf_model, rf_cols)\n",
    "gbm_pred = predict_on_test_set(gbm_model, gbm_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking weighted average of output from two models\n",
    "y_pred = np.round(.20*rf_pred + .80*gbm_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output predictions for submission\n",
    "df_test['count'] = y_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('output5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
